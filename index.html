<!DOCTYPE html>
<html>
<head>
    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LKHQ29GQWX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-LKHQ29GQWX');
  </script>
  
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Imagine-2-Drive: Leveraging High-Fidelity World Models via Multi-Modal Diffusion Policies</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Imagine-2-Drive: Leveraging High-Fidelity World Models via Multi-Modal Diffusion Policies</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://anant-garg205.github.io/">Anant Garg</a><sup>1</sup>,</span>
              <!-- <a href="https://keunhong.com"><mark>Anant Garg</mark></a><sup>1</sup>,</span> -->
            <span class="author-block">
              <a href="https://robotics.iiit.ac.in/faculty_mkrishna/">K. Madhav Krishna</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>International Institute of Information Technology - Hyderabad</span>
          </div>
          <!-- <div class="is-size-5 publication-authors">
            <p><mark>Looking for MS/PhD positions for FY 2025</mark></p>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2411.10171"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/fbwm_pdS-Ss"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/anantagrg/Imagine-2-Drive"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser" style="margin-bottom: -5rem;">

  <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
      <h2 class="title is-3"><i>DiffDreamer</i> Future Frames Denoising Results</h2>
      
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_denoise.mp4"
                type="video/mp4">
      </video>
      <p class="has-text-left">
        Denoising of future frames predictions using <i>DiffDreamer</i>. Frames are predicted according to the input trajectory
        shown as color coded. Unlike single-step models, <i>DiffDreamer</i> predicts future states simultaneously, eliminating compounding errors.
      </p>
    </div>
  </div>

  <hr>

  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content">
        <img id="teaser-image" src="./static/images/teaser.jpg" alt="Teaser Image" height="100%">
      </div>
      <p>
        Using front camera RGB image as the sole input modality, Imagine-2-Drive provides a framework to combine <i>DiffDreamer</i>, a video-diffusion
        based World Model with <i>DPA</i>, a multi-modal diffusion based policy actor. Given a trajectory output by <i>DPA</i>, shown in Red and the
        corresponding predicted future observations from <i>DiffDreamer</i>, the DDPO tries to find an optimal policy by maximizing the cumulative
        sum of rewards from future states. The proposed architecture is shown along with the gradient flow for joint end-to-end training.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          World Model-based Reinforcement Learning
          (WMRL) enables sample efficient policy learning by reducing
          the need for online interactions which can potentially be
          costly and unsafe, especially for autonomous driving. 
          However, existing world models often suffer from low prediction
          fidelity and compounding one-step errors, leading to policy
          degradation over long horizons. Additionally, traditional RL
          policies, often deterministic or single Gaussian-based, fail to
          capture the multi-modal nature of decision-making in complex
          driving scenarios. To address these challenges, we propose
          Imagine-2-Drive, a novel WMRL framework that integrates a
          high-fidelity world model with a multi-modal diffusion-based
          policy actor. It consists of two key components: DiffDreamer,
          a diffusion-based world model that generates future observations simultaneously, mitigating error accumulation, and DPA
          (Diffusion Policy Actor), a diffusion-based policy that models
          diverse and multi-modal trajectory distributions. By training
          DPA within DiffDreamer, our method enables robust policy
          learning with minimal online interactions. We evaluate our
          method in CARLA using standard driving benchmarks and
          demonstrate that it outperforms prior world model baselines,
          improving Route Completion and Success Rate by 15% and 20% respectively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- <iframe src="https://www.youtube.com/embed/56etmpWrnFg" -->
          <iframe src="https://youtube.com/embed/fbwm_pdS-Ss"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">

  <div class="columns is-centered has-text-centered">
    <div class="column is-two-fifths">
      <h2 class="title is-3"><i>DiffDreamer</i> Future Frames Prediction Results</h2>
      
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_prediction.mp4"
                type="video/mp4">
      </video>
      <p class="has-text-left">
        Future obervation predictions from the <i>DiffDreamer</i> World Model, conditioned on the
        input trajectory and current observations. Demonstrates the 
        <i>DiffDreamer's</i> ability to accurately predict future observations based on
        the provided context, highlighting its robust trajectory prediction capabilities.
      </p>
    </div>
  </div>

  <!-- <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
      <h2 class="title is-3">VISTA Future Frames Denoising Results</h2>
      <p class="has-text-left">
        Future obervation predictions from the VISTAPlan World Model, conditioned on the
        input trajectory and current observations. Demonstrates the 
        VISTAPlan’s ability to accurately predict future observations based on
        the provided context, highlighting its robust trajectory prediction capabilities.
      </p>
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_denoise.mp4"
                type="video/mp4">
      </video>
    </div>
  </div> -->

  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Long Run Demo</h2>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/i2d_demo2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <h2 class="title is-3">Multi-Modal Demo</h2>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/i2d_demo_multi_modal_1.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <div class="columns is-centered">
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{garg2025imagine2driveleveraginghighfidelityworld,
        title={Imagine-2-Drive: Leveraging High-Fidelity World Models via Multi-Modal Diffusion Policies}, 
        author={Anant Garg and K Madhava Krishna},
        year={2025},
        eprint={2411.10171},
        archivePrefix={arXiv},
        primaryClass={cs.RO},
        url={https://arxiv.org/abs/2411.10171}
  }</code></pre>
    </div>
  </section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
